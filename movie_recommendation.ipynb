{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0dfb561-aaad-4987-b4cb-07e519f48805",
   "metadata": {},
   "source": [
    "# IDEATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef318f-ce99-401a-8ca4-6bad41e60a1c",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38986ba2-f74a-4470-adab-06da8e84a50f",
   "metadata": {},
   "source": [
    "A movie recommendation system is a software tool that proposes films to users based on their preferences, past viewing habits, and other relevant information. It assists users in finding new films that correspond with their interests, resulting in a more tailored and captivating entertainment experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff2852-d67c-40fe-ad39-b7b3c5e0c240",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdd401-e23e-4d17-a712-6f708f79b77a",
   "metadata": {},
   "source": [
    "This notebook aims to create a **Movie Recommendation System** using content-based filtering approach on the TMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c97573-1ad1-4442-bdb6-df60d18bbf67",
   "metadata": {},
   "source": [
    "Throughout the notebook, we will explore methods for vectorizing movie features, developing similarity metrics to gauge movie similarity, and constructing a recommendation mechanism. By the end, the goal is to have a fully operational movie recommendation system that offers personalized movie suggestions, thereby enhancing the overall movie-viewing experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b94136-67ee-4af7-be8a-df8992b8fcfb",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71de65-1ca1-4248-8b8b-867bd0fe155b",
   "metadata": {},
   "source": [
    "## About dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53de3d-4a27-403f-b658-2615c83f592e",
   "metadata": {},
   "source": [
    "The datasets were scrapped from official **IMDB website**. It provides detailed metadata including:\n",
    "- Title\n",
    "- Genres\n",
    "- Rating\n",
    "- Description\n",
    "- Release Year\n",
    "- Director\n",
    "- Main Cast\n",
    "- Url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c587c8-9aea-45e7-801d-f7fa23139f03",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b9fff-7ecc-4971-afc3-2e9e905e77a4",
   "metadata": {},
   "source": [
    "**Notice**: we will be using **Python** program for this study.\n",
    "\n",
    "To begin, let’s prepare by loading the necessary python packages, libraries, and some pre-defined functions for the project. After that we’ll then import the data from **/datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe7624-9685-478a-9c99-9500897e3859",
   "metadata": {},
   "source": [
    "### Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c64b25-26ff-4624-bd5f-6b032d3ec34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce52290b-b36b-45ad-b725-d4a765f6b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter Stemmer for handling repeated/stemmed words in tags feature\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def concat_csv_files(folder_path, pattern=\"*.csv\"):\n",
    "    \"\"\"\n",
    "    Concatenate all CSV files in a specified folder into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing CSV files.\n",
    "        pattern (str): Pattern to match file names (default is '*.csv').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A single DataFrame containing all rows from matched CSV files.\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(folder_path, pattern))  # Find all matching files\n",
    "    df_list = [pd.read_csv(file) for file in csv_files]         # Read each CSV file\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)         # Concatenate into one DataFrame\n",
    "    return combined_df\n",
    "\n",
    "def to_snake_case_columns(df):\n",
    "    \"\"\"\n",
    "    Convert all column names in a DataFrame to snake_case format.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with original column names.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with column names converted to snake_case.\n",
    "    \"\"\"\n",
    "    df.columns = [\n",
    "        re.sub(r'\\W+', '_', col.strip().lower())  # Remove special characters, lowercase, replace spaces with underscores\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "def drop_incomplete_rows(df):\n",
    "    \"\"\"\n",
    "    Drop rows where any cell is missing or invalid (NaN, 'NAN', 'None', or empty string).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame that may contain missing/incomplete data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with incomplete rows removed.\n",
    "    \"\"\"\n",
    "    df_cleaned = df.replace(['NAN', 'None', ''], np.nan)  # Standardize invalid entries as NaN\n",
    "    df_cleaned = df_cleaned.dropna(how='any')             # Drop any row with at least one NaN\n",
    "    return df_cleaned\n",
    "\n",
    "def split_column_values(df, columns):\n",
    "    \"\"\"\n",
    "    Split comma-separated string values into lists for specified columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame containing string values.\n",
    "        columns (list): List of column names to be split into lists.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with specified columns containing list of values.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: [v.strip() for v in x.split(',')] if pd.notnull(x) else []\n",
    "        )  # Split by comma and trim whitespace\n",
    "    return df\n",
    "    \n",
    "def stem(text):\n",
    "    \"\"\"\n",
    "    Applies stemming to each word in the input text using the PorterStemmer.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): A string of space-separated words.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with each word stemmed (reduced to its root form).\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    for i in text.split():          # Split the text into individual words\n",
    "        y.append(ps.stem(i))        # Apply stemming to each word and collect the result\n",
    "    return \" \".join(y)              # Join the stemmed words back into a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862762c-d398-4d10-aaea-3b1bc8a019d2",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53ad8fa-08e9-4b5b-adf5-cbad4514102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All your CSV files are in the 'scrap_datasets/' directory\n",
    "dataset = concat_csv_files(\"scrap_datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba315a0-b042-4ca8-b480-4b56100a5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f82d45-7d17-4ebe-8752-6bcadb128f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column names to snake_case\n",
    "dataset = to_snake_case_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b468a5bf-d57c-40f0-bc8f-5e37338c17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"movie_id\" column\n",
    "dataset.loc[:, \"movie_id\"] = dataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6301de9-573b-4261-af5d-a470c200088a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>director</th>\n",
       "      <th>main_cast</th>\n",
       "      <th>url</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Nine noble families fight for control over the...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emilia Clarke, Peter Dinklage, Kit Harington</td>\n",
       "      <td>https://www.imdb.com/title/tt0944947/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                     genre  rating  \\\n",
       "0  Game of Thrones  Action, Adventure, Drama     9.2   \n",
       "\n",
       "                                         description  release_year director  \\\n",
       "0  Nine noble families fight for control over the...        2011.0      NaN   \n",
       "\n",
       "                                      main_cast  \\\n",
       "0  Emilia Clarke, Peter Dinklage, Kit Harington   \n",
       "\n",
       "                                     url  movie_id  \n",
       "0  https://www.imdb.com/title/tt0944947/         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first row\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562b64a-b87f-4945-86fc-8cccfa3b0d06",
   "metadata": {},
   "source": [
    "**Since we will implement content-based filtering, we will select only those features that relevant to the content of the movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947a4fda-473b-46fa-b454-7610791193b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns only those that relevant to the content of the movie\n",
    "dataset = dataset[[\"movie_id\", \"title\", \"genre\", \"description\", \"director\", \"main_cast\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eda94dd-cede-454d-8aad-8fb2adcb5fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9671 entries, 0 to 9670\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   movie_id     9671 non-null   int64 \n",
      " 1   title        9671 non-null   object\n",
      " 2   genre        9666 non-null   object\n",
      " 3   description  9555 non-null   object\n",
      " 4   director     9257 non-null   object\n",
      " 5   main_cast    9363 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 453.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check dataset info\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76117d-d570-44ae-b286-42f689354995",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd17c58-c942-45c6-81a8-b4f109f89d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any movies contain null value\n",
    "dataset = drop_incomplete_rows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d017ea5-5fe9-4617-8438-d132e4e89148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the split_column_values to specific columns (convert string of those value to array)\n",
    "dataset = split_column_values(dataset, [\"genre\", \"director\", \"main_cast\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d96394-63a9-4c57-9416-f2dcda0b05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each word of \"description\" to an array\n",
    "dataset[\"description\"] = dataset[\"description\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73799df-95fe-438b-bc3d-7e0f96006c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>main_cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "      <td>[as, the, clone, wars, nears, its, end, obiwan...</td>\n",
       "      <td>[George Lucas]</td>\n",
       "      <td>[Hayden Christensen, Natalie Portman, Ewan McG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                         title  \\\n",
       "1         1  Star Wars: Episode III - Revenge of the Sith   \n",
       "\n",
       "                          genre  \\\n",
       "1  [Action, Adventure, Fantasy]   \n",
       "\n",
       "                                         description        director  \\\n",
       "1  [as, the, clone, wars, nears, its, end, obiwan...  [George Lucas]   \n",
       "\n",
       "                                           main_cast  \n",
       "1  [Hayden Christensen, Natalie Portman, Ewan McG...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c78429c-9f6c-49f7-9810-f0c02f3fa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing \" \" (spaces) between Words from features\n",
    "dataset[\"main_cast\"] = dataset[\"main_cast\"].apply(lambda x: [i.strip().replace(\" \", \"\") for i in x])\n",
    "dataset[\"director\"] = dataset[\"director\"].apply(lambda x: [i.strip().replace(\" \", \"\") for i in x])\n",
    "dataset[\"genre\"] = dataset[\"genre\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc5b9af-0d13-41c8-bf29-50265b068dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>main_cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "      <td>[as, the, clone, wars, nears, its, end, obiwan...</td>\n",
       "      <td>[GeorgeLucas]</td>\n",
       "      <td>[HaydenChristensen, NataliePortman, EwanMcGregor]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                         title  \\\n",
       "1         1  Star Wars: Episode III - Revenge of the Sith   \n",
       "\n",
       "                          genre  \\\n",
       "1  [Action, Adventure, Fantasy]   \n",
       "\n",
       "                                         description       director  \\\n",
       "1  [as, the, clone, wars, nears, its, end, obiwan...  [GeorgeLucas]   \n",
       "\n",
       "                                           main_cast  \n",
       "1  [HaydenChristensen, NataliePortman, EwanMcGregor]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a69bfb7b-be69-4beb-b095-cebbd832d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column \"tags\"\n",
    "def create_tags(row):\n",
    "    return row['description'] + row['genre'] *  2 + row['main_cast'] * 3 + row['director'] * 2\n",
    "\n",
    "dataset[\"tags\"] = dataset.apply(create_tags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b7378b5-ff4a-4747-b0dd-58bd6dcefc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset\n",
    "new_dataset = dataset[[\"movie_id\", \"title\", \"tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49743dd0-deee-42c7-91e0-1b34ea7985e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.loc[:, \"tags\"] = new_dataset[\"tags\"].apply(lambda x: \" \".join(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4700427c-d305-4850-8410-bce907052bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>as the clone wars nears its end obiwan kenobi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                         title  \\\n",
       "1         1  Star Wars: Episode III - Revenge of the Sith   \n",
       "\n",
       "                                                tags  \n",
       "1  as the clone wars nears its end obiwan kenobi ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09169a24-1459-4077-ab2a-96430e3f1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataset\n",
    "new_dataset.reset_index(drop=True, inplace=True)\n",
    "new_dataset.to_csv(\"./scrap_datasets/clean_datasets/cleaned_imdb_scrapped_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad24beb-b521-404f-bb2b-6eeed4a1a834",
   "metadata": {},
   "source": [
    "# DEVELOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "432b67e7-e66e-4b2f-bccc-36fac6d3f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stem to the dataset\n",
    "new_dataset.loc[:, \"tags\"] = new_dataset[\"tags\"].apply(stem)\n",
    "\n",
    "# Vectorization: Creating each movie as a Vector\n",
    "cv = CountVectorizer(max_features=5000, stop_words=\"english\")\n",
    "\n",
    "# Vectorization the \"tags\" of dataset\n",
    "vector = cv.fit_transform(new_dataset[\"tags\"]).toarray()\n",
    "\n",
    "# Calculating Cosine Angle between vectors\n",
    "similar = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f276258b-7c59-4af2-a91c-b5e138b3965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend top N movies similar to the given movie title.\n",
    "    \n",
    "    Parameters:\n",
    "        movie (str): The title of the movie to base recommendations on.\n",
    "        top_n (int): Number of recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of recommended movie titles.\n",
    "    \"\"\"\n",
    "    movie = movie.strip().lower()\n",
    "    match = new_dataset[new_dataset[\"title\"].str.lower().str.strip() == movie]\n",
    "    \n",
    "    if match.empty:\n",
    "        return f\"Movie '{movie}' not found in the dataset.\"\n",
    "    \n",
    "    movie_index = match.index[0]\n",
    "    distances = similar[movie_index]\n",
    "    movie_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:top_n+1]\n",
    "    \n",
    "    recommendations = [new_dataset.iloc[i[0]].title for i in movie_list]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa91ee5-ba12-4d57-9611-6db9815f71fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shrek 2',\n",
       " 'Shrek Forever After',\n",
       " 'Shrek the Third',\n",
       " 'The Chipmunk Adventure',\n",
       " 'The Pirates Who Don&apos;t Do Anything: A VeggieTales Movie']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"Shrek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59c21ba2-1145-4cf7-bda4-1cefce6cfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_dataset.to_dict(), open(\"./output/movies.pkl\", \"wb\"))\n",
    "pickle.dump(similar, open(\"./output/similar.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4ae1d-5d79-4d4f-9a84-0418e4098e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
